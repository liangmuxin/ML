{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is not the originally Jupyter Notebook\n",
    "#Some procedure may take long time\n",
    "\n",
    "import random\n",
    "import numpy as np  \n",
    "import struct  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "#import some tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#These functions read the data\n",
    "def loadImageSet(filename):  \n",
    "    print(\"load image set\",filename) \n",
    "    binfile= open(filename, 'rb')  \n",
    "    buffers = binfile.read()  \n",
    "   \n",
    "    head = struct.unpack_from('>IIII' , buffers ,0)  \n",
    "   \n",
    "    offset = struct.calcsize('>IIII')  \n",
    "    imgNum = head[1]  \n",
    "    width = head[2]  \n",
    "    height = head[3]  \n",
    "    #[60000]*28*28  \n",
    "    bits = imgNum * width * height  \n",
    "    bitsString = '>' + str(bits) + 'B' #like '>47040000B'  \n",
    "   \n",
    "    imgs = struct.unpack_from(bitsString,buffers,offset)  \n",
    "   \n",
    "    binfile.close()  \n",
    "    imgs = np.reshape(imgs,[imgNum,1,width*height])  \n",
    "    print(\"load imgs finished\")  \n",
    "    return imgs  \n",
    "   \n",
    "def loadLabelSet(filename):  \n",
    "   \n",
    "    print(\"load label set\",filename) \n",
    "    binfile = open(filename, 'rb')  \n",
    "    buffers = binfile.read()  \n",
    "   \n",
    "    head = struct.unpack_from('>II' , buffers ,0)  \n",
    "    imgNum=head[1]  \n",
    "   \n",
    "    offset = struct.calcsize('>II')  \n",
    "    numString = '>'+str(imgNum)+\"B\"  \n",
    "    labels = struct.unpack_from(numString , buffers , offset)  \n",
    "    binfile.close()  \n",
    "    labels = np.reshape(labels,[imgNum,1])  \n",
    "   \n",
    "    print('load label finished')  \n",
    "    return labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot25(images,labels):# plot 25 train data\n",
    "    plt.figure(figsize=(20,4))\n",
    "    for index, (image, label) in enumerate(zip(imgs[0:25], labels[0:25])):\n",
    "        plt.subplot(1, 25, index + 1)\n",
    "        plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "        plt.title(label, fontsize = 20)\n",
    "    plt.show()    \n",
    "def plotrandom(images, labels): #plot random 15 test data\n",
    "    plt.figure(figsize=(20,4))\n",
    "    for i in range(0,15):\n",
    "        num = random.randrange(0, len(images))\n",
    "        plt.subplot(1,15,i+1)\n",
    "        plt.imshow(np.reshape(images[num], (28,28)), cmap = plt.cm.gray)\n",
    "    plt.show()\n",
    "#This functions are for 1_c_1 and 1_c_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn(train_data,train_label):\n",
    "    X = train_data\n",
    "    Y = train_label\n",
    "    Knn = KNeighborsClassifier(n_neighbors = 5, algorithm = \"ball_tree\", p=2).fit(X,Y)\n",
    "    return Knn\n",
    "#This function generate a knn where k = 5, algorithm = balltree p=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load image set train-images.idx3-ubyte\n",
      "load imgs finished\n",
      "load image set t10k-images.idx3-ubyte\n",
      "load imgs finished\n",
      "load label set train-labels.idx1-ubyte\n",
      "load label finished\n",
      "load label set t10k-labels.idx1-ubyte\n",
      "load label finished\n"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "imgs = loadImageSet(\"train-images.idx3-ubyte\")\n",
    "imgts = loadImageSet(\"t10k-images.idx3-ubyte\")  \n",
    "labels = loadLabelSet(\"train-labels.idx1-ubyte\") \n",
    "labelts = loadLabelSet(\"t10k-labels.idx1-ubyte\")\n",
    "train_data = np.reshape(imgs,(60000,28*28))\n",
    "test_data = np.reshape(imgts,(10000,28*28))\n",
    "train_label = np.reshape(labels, 60000)\n",
    "test_label = np.reshape(labelts, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyper\\Anaconda3\\envs\\python3\\lib\\site-packages\\matplotlib\\pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#work for 1_C_2, plot 5 nearest neighbors\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=5)\n",
    "neigh.fit(train_data)\n",
    "nnlist = []\n",
    "for i in test_data[0:10]:\n",
    "    a = neigh.kneighbors(np.reshape(i, (1,-1)),n_neighbors=5, return_distance=False)\n",
    "    for itm in a[0]:\n",
    "        nnlist.append(itm)\n",
    "def nbplot(indata, inlist, num):\n",
    "    plt.figure(figsize=(10,2))\n",
    "    cnt=0\n",
    "    for i in inlist:\n",
    "        plt.subplot(1,5,cnt+1)\n",
    "        plt.imshow(np.reshape(indata[i], (28,28)))\n",
    "        cnt+=1\n",
    "    plt.savefig(\"c2_\"+str(num)+\".png\")\n",
    "    cnt=0\n",
    "nbplot(train_data,nnlist[0:5],1)\n",
    "nbplot(train_data, nnlist[5:10],2)\n",
    "nbplot(train_data, nnlist[10:15],3)\n",
    "nbplot(train_data, nnlist[15:20],4)\n",
    "nbplot(train_data, nnlist[20:25],5)\n",
    "nbplot(train_data, nnlist[25:30],6)\n",
    "nbplot(train_data, nnlist[30:35],7)\n",
    "nbplot(train_data, nnlist[35:40],8)\n",
    "nbplot(train_data, nnlist[40:45],9)\n",
    "nbplot(train_data, nnlist[45:50],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to finish 1_C_3, I tested k's sepeartely in 5 group and recorded the result manually\n",
    "testinggroup1=[1,201,401,601,801,1001,1201,1401,1601,1801,2001]\n",
    "testinggroup2=[2201,2401,2601,2801,3001,3201,3401,3601,3801,4001]\n",
    "testinggroup3=[4201,4401,4601,4801,5001,5201,5401,5601,5801,6001]\n",
    "testinggroup4=[6201,6401,6601,6801,7001,7201,7401,7601,7801,8001]\n",
    "testinggroup5=[8201,8401,8601,8801,9001,9201,9401,9601,9801,10001]\n",
    "def knnkaccuracy(train_data,train_label,test_data, test_label, kval):\n",
    "    X = train_data\n",
    "    Y = train_label\n",
    "    knn = KNeighborsClassifier(n_neighbors = kval, algorithm = \"ball_tree\", p=2).fit(X,Y)\n",
    "    print(\"testset accuracy\")\n",
    "    y_pre = knn.predict(test_data)\n",
    "    tmp = metrics.accuracy_score(y_pre, test_label)\n",
    "    print(\"trainset accuracy\")\n",
    "    y_pre = knn.predict(train_data)\n",
    "    tmp = metrics.accuracy_score(y_pre, train_label)\n",
    "#this function is used for printing accuracy\n",
    "print(\"start\")\n",
    "for k in testinggroup5:#this wiil be rewritten and changed for 5 testing groups\n",
    "    print(\"start for k = \", k)\n",
    "    a = knnkaccuracy(train_data, train_label, test_data, test_label, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#After some calculations, I got the error rate from accuracy and 1/k\n",
    "trainerror=[0.0,1-0.9616,0.0735,0.0797,0.0858,0.092,0.0981,0.1043,0.1105,0.1166,0.1228,0.1289,0.1351,0.1413,0.1474,0.1536,0.1597,0.1659,0.1721,0.1782,0.1844,0.1905,0.1967,0.2029,0.209,0.2152,0.2213,0.2275,0.2337,0.2398,0.246,0.2521,0.2583,0.2645,0.2706,0.2768,0.2829,0.2891,0.2953,0.3014,0.3076,0.3137,0.3199,0.3261,0.3322,0.3384,0.3445,0.3507,0.3569,0.363,0.3692,0.372]\n",
    "testerror=[0.0309,1-0.9688,0.0709,0.0887,0.1094,0.1146,0.127,0.1373,0.1457,0.1557,0.1642,0.1719,0.1719,0.1779,0.1838,0.1896,0.1954,0.2012,0.2068,0.2124,0.218,0.2235,0.2289,0.2343,0.2396,0.2448,0.25,0.2552,0.2602,0.2652,0.2702,0.2751,0.2799,0.2847,0.2894,0.294,0.2986,0.3032,0.3076,0.312,0.3164,0.3207,0.3249,0.3291,0.3332,0.3372,0.3412,0.3452,0.349,0.3478,0.3502,0.3508] \n",
    "klist=[1.0, 0.2,0.004975124378109453, 0.0024937655860349127, 0.0016638935108153079, 0.0012484394506866417, 0.000999000999000999, 0.0008326394671107411, 0.0007137758743754461, 0.0006246096189881324, 0.000555247084952804, 0.0004997501249375312, 0.00045433893684688776, 0.00041649312786339027, 0.00038446751249519417, 0.0003570153516601214, 0.0003332222592469177, 0.00031240237425804435, 0.00029403116730373417, 0.00027770063871146905, 0.00026308866087871614, 0.00024993751562109475, 0.00023803856224708403, 0.00022722108611679165, 0.00021734405564007825, 0.00020828993959591752, 0.0001999600079984003, 0.00019227071716977504, 0.00018515089798185522, 0.00017853954650955185, 0.00017238407171177384, 0.00016663889351774705, 0.00016126431220770844, 0.0001562255897516013, 0.0001514921981517952, 0.00014703720041170417, 0.00014283673760891302, 0.00013886960144424384, 0.00013511687609782462, 0.00013156163662675965, 0.00012818869375721061, 0.00012498437695288088, 0.00012193634922570419, 0.00011903344839900012, 0.0001162655505173817, 0.00011362345188046812, 0.00011109876680368848, 0.00010868383871318335, 0.00010637166258908626, 0.00010415581710238516, 0.00010203040506070809, 9.999000099990002e-05]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#And the plotting for k\n",
    "plt.figure(figsize=(10,2))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(klist, testerror, 'o-')\n",
    "plt.ylabel(\"test error\")\n",
    "plt.xlabel(\"1/k\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(klist, trainerror, 'o-')\n",
    "plt.ylabel(\"train error\")\n",
    "plt.xlabel(\"1/k\")\n",
    "plt.savefig(\"errorplot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9688\n"
     ]
    }
   ],
   "source": [
    "#by the way, I choose k = 5，Euclidean metric，alltraindata and alltestdata as my default knn because it has the best testing accuracy by now, and I predict for the \n",
    "myknn = knn(train_data, train_label)\n",
    "y_pred = myknn.predict(test_data)\n",
    "print(metrics.accuracy_score(y_pred, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1_c_4, test on different size, I also did manually record on this\n",
    "sizelist=[5000,10000,15000,20000,25000,30000,35000,40000,45000,50000,55000]\n",
    "acclist = []\n",
    "for val in sizelist:\n",
    "    print(\"size = \", val)\n",
    "    X = train_data[0:val]\n",
    "    Y = train_label[0:val]\n",
    "    myknn =knn(X,Y)\n",
    "    y_pred = myknn.predict(test_data)\n",
    "    t = metrics.accuracy_score(y_pred, test_label)\n",
    "    acclist.append(t)\n",
    "    print(\"accuracy: \", t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this will plot test error rate vs trainset size\n",
    "sizelist=[5000,10000,15000,20000,25000,30000,35000,40000,45000,50000,55000]\n",
    "acclist = [0.9325,0.94420000000000004,0.95189999999999997,0.95489999999999997,0.95930000000000004,0.9627,0.96519999999999995,0.96530000000000005,0.96609999999999996,0.96640000000000004,0.96850000000000003]\n",
    "acclist.append(0.9688)\n",
    "errlist =[]\n",
    "for a in acclist:\n",
    "    errlist.append(1-a)\n",
    "sizelist.append(60000)\n",
    "plt.figure()\n",
    "plt.plot(sizelist, errlist,'o-')\n",
    "plt.xlabel(\"trainset size\")\n",
    "plt.ylabel(\"testset error rate\")\n",
    "plt.savefig(\"err_vs_size.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyper\\Anaconda3\\envs\\python3\\lib\\site-packages\\matplotlib\\pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#1_d This is to plot some incorrect identification of images, I take those that are predict to 2 but actually not\n",
    "incorrect = np.where((y_pred == 2) & (test_label!=2))[0]\n",
    "plt.figure(figsize=(10,3))\n",
    "cnt=0\n",
    "for val in incorrect[0:5]:\n",
    "    plt.subplot(1,5,cnt+1)\n",
    "    plt.imshow(np.reshape(test_data[val], (28,28)))\n",
    "    plt.xlabel(str(test_label[val]))\n",
    "    \n",
    "    cnt+=1\n",
    "plt.savefig(\"wrongimgs.png\")\n",
    "\n",
    "wrneigh = NearestNeighbors(n_neighbors=5)\n",
    "wrneigh.fit(train_data)\n",
    "wrlist = []\n",
    "for i in incorrect[0:5]:\n",
    "    a = neigh.kneighbors(np.reshape(test_data[i], (1,-1)),n_neighbors=5, return_distance=False)\n",
    "    for itm in a[0]:\n",
    "        wrlist.append(itm)\n",
    "\n",
    "nbplot(train_data,wrlist[0:5],\"1w\")\n",
    "nbplot(train_data, wrlist[5:10],\"2w\")\n",
    "nbplot(train_data, wrlist[10:15],\"3w\")\n",
    "nbplot(train_data, wrlist[15:20],\"4w\")\n",
    "nbplot(train_data, wrlist[20:25],\"5w\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Euclidean_distance is 0.9222\n",
      "Accuracy for manhattan_distance is 0.9098\n",
      "Accuracy for log10(p) =  0.1 is 0.915\n",
      "Accuracy for log10(p) =  0.2 is 0.9192\n",
      "Accuracy for log10(p) =  0.3 is 0.922\n",
      "Accuracy for log10(p) =  0.4 is 0.9246\n",
      "Accuracy for log10(p) =  0.5 is 0.9268\n",
      "Accuracy for log10(p) =  0.6 is 0.9304\n",
      "Accuracy for log10(p) =  0.7 is 0.9322\n",
      "Accuracy for log10(p) =  0.8 is 0.9344\n",
      "Accuracy for log10(p) =  0.9 is 0.9342\n",
      "Accuracy for log10(p) =  1 is 0.9342\n",
      "Accuracy for Chebyshev_distance is 0.0912\n"
     ]
    }
   ],
   "source": [
    "#1_e Testing on new distances, for easier calculation, I reduced the size of training and testing set\n",
    "testknn = KNeighborsClassifier(n_neighbors = 5, algorithm = \"ball_tree\", p=2).fit(train_data[0:10000],train_label[0:10000])\n",
    "test_pred = testknn.predict(test_data[0:5000])\n",
    "print(\"Accuracy for Euclidean_distance is\",metrics.accuracy_score(test_pred, test_label[0:5000]))\n",
    "\n",
    "testknn = KNeighborsClassifier(n_neighbors = 5, algorithm = \"ball_tree\", p=1).fit(train_data[0:10000],train_label[0:10000])\n",
    "test_pred = testknn.predict(test_data[0:5000])\n",
    "print(\"Accuracy for manhattan_distance is\",metrics.accuracy_score(test_pred, test_label[0:5000]))\n",
    "\n",
    "plist = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "for pp in plist:\n",
    "    testknn = KNeighborsClassifier(n_neighbors = 5, algorithm = \"ball_tree\", p=10**pp).fit(train_data[0:10000],train_label[0:10000])\n",
    "    test_pred = testknn.predict(test_data[0:5000])\n",
    "    print(\"Accuracy for log10(p) = \", pp, \"is\", metrics.accuracy_score(test_pred, test_label[0:5000]))\n",
    "    \n",
    "testknn = KNeighborsClassifier(n_neighbors = 5, algorithm = \"ball_tree\", p=1000).fit(train_data[0:10000],train_label[0:10000])\n",
    "test_pred = testknn.predict(test_data[0:5000])\n",
    "print(\"Accuracy for Chebyshev_distance is\",metrics.accuracy_score(test_pred, test_label[0:5000]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.spatial.distance\n",
    "from sklearn.metrics import pairwise_distances\n",
    "# pairwise_distances(train_data, metric=\"mahalanobis\")\n",
    "# neigh = NearestNeighbors(n_neighbors=5)\n",
    "# neigh.fit(test_data)\n",
    "# print(\"Accuracy for Mahalanobis_distance is\",metrics.accuracy_score(test_pred, test_label[0:5000]))\n",
    "# testknn = KNeighborsClassifier(n_neighbors = 5, metric=\"nang\").fit(train_data[0:10000],train_label[0:10000])\n",
    "# test_pred = testknn.predict(test_data[0:5000])\n",
    "# print(\"Accuracy for Hausdroff_distance is\",metrics.accuracy_score(test_pred, test_label[0:5000])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Chebyshev_distance is using invsesed distance is 0.092\n"
     ]
    }
   ],
   "source": [
    "#1_f use another decision\n",
    "testknn = KNeighborsClassifier(n_neighbors = 5, algorithm = \"ball_tree\",weights = \"distance\", p=2).fit(train_data[0:10000],train_label[0:10000])\n",
    "test_pred = testknn.predict(test_data[0:5000])\n",
    "print(\"Accuracy for Euclidean_distance is using invsesed distance is\",metrics.accuracy_score(test_pred, test_label[0:5000]))\n",
    "\n",
    "testknn = KNeighborsClassifier(n_neighbors = 5, algorithm = \"ball_tree\",weights = \"distance\", p=1).fit(train_data[0:10000],train_label[0:10000])\n",
    "test_pred = testknn.predict(test_data[0:5000])\n",
    "print(\"Accuracy for manhattan_distance is using invsesed distance is\",metrics.accuracy_score(test_pred, test_label[0:5000]))\n",
    "\n",
    "testknn = KNeighborsClassifier(n_neighbors = 5, algorithm = \"ball_tree\",weights = \"distance\", p = 1000).fit(train_data[0:10000],train_label[0:10000])\n",
    "test_pred = testknn.predict(test_data[0:5000])\n",
    "print(\"Accuracy for Chebyshev_distance is using invsesed distance is\",metrics.accuracy_score(test_pred, test_label[0:5000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
